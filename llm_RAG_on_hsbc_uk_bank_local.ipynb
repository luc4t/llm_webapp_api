{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QZ_E1Ma1jKYT",
        "-6LGAl2AGj4j",
        "Ooplt3-YJJRb",
        "3klGmAwEDxDY",
        "gUMZZ3XKSb1A"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luc4t/llm_webapp_api/blob/main/llm_RAG_on_hsbc_uk_bank_local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local LLM using RAG with HSBC UK Bank dataset\n",
        "Hi, my name is Vladimir, find implementation of RAG with local LLM.\n",
        "\n",
        "Answering questions on on [HSBC bank](https://www.hsbc.co.uk/) services using local LLM. Basically assistant that can help users with their questions with the bank.\n",
        "\n",
        "Google Colab subscription is advised.\n",
        "T4 GPU is enough. Overall usage is 12GB GPU RAM."
      ],
      "metadata": {
        "id": "h7OBSYLoGbEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs, imports"
      ],
      "metadata": {
        "id": "QZ_E1Ma1jKYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken FlagEmbedding ctransformers[cuda] huggingface-hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI1vDVPCjeZT",
        "outputId": "03703d10-f150-4e2d-d5b6-5afa61ca6418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.8 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.8 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting FlagEmbedding\n",
            "  Downloading FlagEmbedding-1.2.5.tar.gz (37 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ctransformers[cuda]\n",
            "  Downloading ctransformers-0.2.27-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding) (4.38.1)\n",
            "Collecting datasets (from FlagEmbedding)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.20.1 (from FlagEmbedding)\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence_transformers (from FlagEmbedding)\n",
            "  Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ctransformers[cuda]) (9.0.0)\n",
            "Collecting nvidia-cublas-cu12 (from ctransformers[cuda])\n",
            "  Downloading nvidia_cublas_cu12-12.3.4.1-py3-none-manylinux1_x86_64.whl (412.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.6/412.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12 (from ctransformers[cuda])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (867 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.7/867.7 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (23.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (1.25.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (0.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->FlagEmbedding) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->FlagEmbedding) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->FlagEmbedding) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->FlagEmbedding) (2.1.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->FlagEmbedding) (0.15.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->FlagEmbedding) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->FlagEmbedding) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->FlagEmbedding)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->FlagEmbedding) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->FlagEmbedding) (3.4.1)\n",
            "Collecting multiprocess (from datasets->FlagEmbedding)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->FlagEmbedding) (3.9.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->FlagEmbedding) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->FlagEmbedding) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->FlagEmbedding) (9.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->FlagEmbedding) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->FlagEmbedding) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->FlagEmbedding) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->FlagEmbedding) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->FlagEmbedding) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->FlagEmbedding) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->FlagEmbedding) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->FlagEmbedding) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->FlagEmbedding) (2023.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers->FlagEmbedding) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers->FlagEmbedding) (3.3.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->FlagEmbedding) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->FlagEmbedding) (1.16.0)\n",
            "Building wheels for collected packages: FlagEmbedding\n",
            "  Building wheel for FlagEmbedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for FlagEmbedding: filename=FlagEmbedding-1.2.5-py3-none-any.whl size=43015 sha256=cf46df77176aff428e12a86fe34f59ba14bfc6f4b1d6c62a37d3ae5fa19a89d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/b3/70/bb01bbe4d671974606861835ee82b86c0cf24c92cee749edd6\n",
            "Successfully built FlagEmbedding\n",
            "Installing collected packages: nvidia-cuda-runtime-cu12, nvidia-cublas-cu12, dill, tiktoken, multiprocess, ctransformers, accelerate, datasets, sentence_transformers, FlagEmbedding\n",
            "Successfully installed FlagEmbedding-1.2.5 accelerate-0.27.2 ctransformers-0.2.27 datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.3.4.1 nvidia-cuda-runtime-cu12-12.3.101 sentence_transformers-2.5.1 tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ctransformers import AutoModelForCausalLM\n",
        "from FlagEmbedding import FlagModel, FlagReranker\n",
        "import re\n",
        "import tiktoken\n",
        "import os\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pickle"
      ],
      "metadata": {
        "id": "nBDSHAzNjJvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HSBC bank dataset\n",
        "Get hsbc bank dataset from this google drive: https://drive.google.com/file/d/1gFVEzyTBgDmMP48SjySA3skq8nwRxZZw/view?usp=sharing\n",
        "\n",
        "It is a text file, upload it here using function below."
      ],
      "metadata": {
        "id": "-6LGAl2AGj4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "-GOTEDIMnbiN",
        "outputId": "c8ac9b69-7ce1-4b83-9731-986a75c3228c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e85a71cb-687b-4647-8fe5-e8781c7cf072\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e85a71cb-687b-4647-8fe5-e8781c7cf072\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset_hsbc to dataset_hsbc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = list(uploaded.keys())[0]\n",
        "with open(filename, 'r') as f:\n",
        "    document = f.read()"
      ],
      "metadata": {
        "id": "cWtP9m9unZNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_chunks = document.split('########')\n",
        "print('Number of texts:', len(document_chunks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbWUXpnVobB9",
        "outputId": "a95a1e2d-4f07-43a9-9f69-a9652c163b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts: 565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "chunks_sizes = [len(chunk) for chunk in document_chunks]\n",
        "percentile_50th = np.percentile(chunks_sizes, 50)\n",
        "plt.hist(chunks_sizes, bins=30)\n",
        "plt.title('Distribution of text-chunks length, with 50th percentile')\n",
        "plt.xlabel('Length of text-chunk in characters')\n",
        "plt.axvline(x = percentile_50th, color = 'red', linestyle = '--', alpha = 0.5)\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)\n",
        "plt.show();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "WNXNaoHzq5sZ",
        "outputId": "f7993c62-e2bc-4006-84ad-1690f3087373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run local llm\n",
        "Test simple query"
      ],
      "metadata": {
        "id": "Ooplt3-YJJRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "About beluga https://huggingface.co/TheBloke/StableBeluga-7B-GGUF\n",
        "\n",
        "Documentation on ctransformers https://pypi.org/project/ctransformers/#documentation\n",
        "\n",
        "Parameters explained https://huggingface.co/blog/how-to-generate\n",
        "\n",
        "Alternatively how to run locally mistral 7b https://www.automatebard.com/2023/12/18/how-to-get-started-with-mistral-7b-tutorial/"
      ],
      "metadata": {
        "id": "iauNBjh33Llv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download TheBloke/StableBeluga-7B-GGUF stablebeluga-7b.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFYUU4TlVm5B",
        "outputId": "edc6a449-c0a4-4634-db8a-273fb5bfd33e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Consider using `hf_transfer` for faster downloads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\n",
            "downloading https://huggingface.co/TheBloke/StableBeluga-7B-GGUF/resolve/main/stablebeluga-7b.Q4_K_M.gguf to /root/.cache/huggingface/hub/tmptj1fg05h\n",
            "stablebeluga-7b.Q4_K_M.gguf: 100% 4.08G/4.08G [01:26<00:00, 47.4MB/s]\n",
            "./stablebeluga-7b.Q4_K_M.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.abspath('stablebeluga-7b.Q4_K_M.gguf')"
      ],
      "metadata": {
        "id": "8xyYJXzNWkTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Documentation says this beluga input token limit is 4096. Define it.\n",
        "limit_input_tokens = 4096"
      ],
      "metadata": {
        "id": "FWWqhPQxAloP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_ctrans = AutoModelForCausalLM.from_pretrained(model_path, local_files_only=True, gpu_layers=100, context_length=limit_input_tokens, model_type='llama', max_new_tokens=1024)"
      ],
      "metadata": {
        "id": "QfbuLzp559of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "answer = llm_ctrans('Who is the smartest animal on Earth?', top_k=40, top_p=0.4, temperature=0.7)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "OLkktGtA6LhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd79005d-202a-412a-8e7f-c50ef7bdaebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The smartest animal on Earth, according to scientists, is the octopus. These intelligent creatures have been observed solving complex problems and using tools in their natural environment. They are also known for their ability to change color and texture to blend into their surroundings, which helps them avoid predators.\n",
            "Octopuses are highly adaptable and can learn from experience, making them one of the most intelligent animals on Earth.\n",
            "CPU times: user 6.17 s, sys: 46.5 ms, total: 6.21 s\n",
            "Wall time: 4.42 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This small model answered pretty quickly, utilizing 7GB GPU RAM. The answer is sane."
      ],
      "metadata": {
        "id": "qyqNnVjAL7DS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG (Retrieval Augmented Generation)\n",
        "Now retriving relevant HSBC information prepare a query for the language model.\n",
        "1. Define query variable.\n",
        "2. Encode into embedding space. Retrieve most similar chunks of text.\n",
        "3. Improve retrieved chunks of text via reranker - rearrange it in an improved order.\n",
        "4. Cook final query (instructions + best chunks + query) in order to feed it into the language model."
      ],
      "metadata": {
        "id": "3klGmAwEDxDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"how do i get student loan\"\n",
        "llm_full_query = ''"
      ],
      "metadata": {
        "id": "3VwI3SmcZhca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize embedding model and reranker beforehand."
      ],
      "metadata": {
        "id": "1BlAqzrbTLi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_model_bge = FlagModel('BAAI/bge-base-en-v1.5',\n",
        "                       use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation"
      ],
      "metadata": {
        "id": "maa9zPqp1jKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reranker = FlagReranker('BAAI/bge-reranker-large', use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation"
      ],
      "metadata": {
        "id": "RNaWdHLy4idV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run RAG"
      ],
      "metadata": {
        "id": "gUMZZ3XKSb1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try bge https://huggingface.co/BAAI/bge-m3 - the best multilangual embeddings according to article https://towardsdatascience.com/openai-vs-open-source-multilingual-embedding-models-e5ccb7c90f05\n",
        "\n",
        "Try matryoshka https://huggingface.co/blog/matryoshka\n",
        "\n",
        "Nice article on search via embeddings using cohere https://medium.com/red-buffer/building-a-multilingual-cross-language-semantic-search-engine-using-cohere-76595ebc679e\n",
        "\n",
        "Try bert embeddings? https://www.analyticsvidhya.com/blog/2023/08/bert-embeddings/"
      ],
      "metadata": {
        "id": "jZ0r9txL4aSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider improved bge https://github.com/michaelfeil/infinity\n",
        "\n",
        "Reranker after retrieval https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/reranker\n",
        "\n",
        "Explore also: https://github.com/huggingface/text-embeddings-inference"
      ],
      "metadata": {
        "id": "g27xkOSX4aFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## encode dataset\n",
        "embeddings_bge = embeddings_model_bge.encode(document_chunks)"
      ],
      "metadata": {
        "id": "5mgQaML-3dYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save bge embeddings dictionary to person_data.pkl file\n",
        "with open('embeddings_bge_hsbc.pkl', 'wb') as fp:\n",
        "    pickle.dump(embeddings_bge, fp)\n",
        "    print('dictionary saved successfully to file')"
      ],
      "metadata": {
        "id": "McMgeAK33dYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('embeddings_bge_hsbc.pkl', 'rb') as fp:\n",
        "    embeddings_bge = pickle.load(fp)"
      ],
      "metadata": {
        "id": "giqxbM1Vz4b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bge_RAG_start = datetime.datetime.now()\n",
        "print(bge_RAG_start)"
      ],
      "metadata": {
        "id": "LQj1q1EDETQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_bge_query = embeddings_model_bge.encode([query])"
      ],
      "metadata": {
        "id": "oROlBTnm0hYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = emb_bge_query @ embeddings_bge.T\n",
        "scores = np.squeeze(scores)"
      ],
      "metadata": {
        "id": "NOGFWBg-0rp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_idx = np.argsort(-scores)\n",
        "max_idx[:8]"
      ],
      "metadata": {
        "id": "ggpWrw8N896o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Query: {query}\")\n",
        "context_chunks_init = []\n",
        "context_scores = []\n",
        "for idx in max_idx[:8]:\n",
        "  print(f\"Score: {scores[idx]:.2f}\")\n",
        "  print(document_chunks[idx])\n",
        "  print(\"--------\")\n",
        "  context_chunks_init.append(document_chunks[idx])\n",
        "  context_scores.append(scores[idx])"
      ],
      "metadata": {
        "id": "fuRPAA_v2Dfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now use reranker on the retrieved chunks of text."
      ],
      "metadata": {
        "id": "phZHoiIHTVfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test reranker to show it's capabilities. Returns similarity scores. With improved ranks.\n",
        "scores_test = reranker.compute_score([['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']])\n",
        "print(scores_test)"
      ],
      "metadata": {
        "id": "Dgllh5mwTDun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make pairs of query and chunks\n",
        "query_and_chunks = [[query, chunk] for chunk in context_chunks_init]"
      ],
      "metadata": {
        "id": "W8O4-B3F4yTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_reranker = reranker.compute_score(query_and_chunks)\n",
        "print(scores_reranker)"
      ],
      "metadata": {
        "id": "URNQfNks5NFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# indexes sorted according to new rank\n",
        "max_idx_reranked = np.argsort(-np.array(scores_reranker))\n",
        "print(max_idx_reranked)"
      ],
      "metadata": {
        "id": "RpIcjK7b5pGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Query: {query}\")\n",
        "context_chunks = []\n",
        "for idx in max_idx_reranked:\n",
        "  print(f\"Score: {scores_reranker[idx]:.2f}\")\n",
        "  print(context_chunks_init[idx])\n",
        "  print(\"--------\")\n",
        "  context_chunks.append(context_chunks_init[idx])"
      ],
      "metadata": {
        "id": "je05CsAJ515Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Order of retrieved chunks improved and became more relevant!\n",
        "\n",
        "Now define prompt template and create final query from reranked chunks in order to feed it to our local llm."
      ],
      "metadata": {
        "id": "jeaDR5CR9TzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"You are a professional consultant at HSBC UK Bank.\n",
        "Use the context to answer the question at the end.\n",
        "Give a very detailed answer.\n",
        "Never mention about context and where information comes from.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\"\"\""
      ],
      "metadata": {
        "id": "oCHXakaQX7fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_chunks_as_str = '\\n###\\n'.join([str(elem) for elem in context_chunks])\n",
        "llm_full_query = prompt_template.format(context=context_chunks_as_str, question=query)"
      ],
      "metadata": {
        "id": "-u-ynZxaeSNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure num of input tokens does not exceed limit.\n",
        "\n",
        "How to calculate num of tokens: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb"
      ],
      "metadata": {
        "id": "CvJWKtYlWnJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tiktoken.get_encoding(\"p50k_base\")\n",
        "num_tokens_template = len(encoding.encode(prompt_template))\n",
        "num_tokens = len(encoding.encode(llm_full_query))\n",
        "print('num_tokens', num_tokens)"
      ],
      "metadata": {
        "id": "CPFSAkFwePtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The logic checks if highest initial score is high enough (0.45), and is relevant to HSBC Bank services.\n",
        "# Also more complex logic is implemented to ensure the full llm query does not exceeds input token limit\n",
        "# i.e. finall llm query is cooked with size < limit_input_tokens\n",
        "correction_num_of_tokens = 500 # additionally decrease num of tokens by this number\n",
        "\n",
        "if context_scores[0]<0.45:\n",
        "  llm_full_query = 'I am HSBC UK Bank assistant and can answer questions related to our Bank. If you have any questions regarding banking services, I will be happy to help. \\nPlease formulate your request.'\n",
        "else:\n",
        "  num_of_chunks = len(context_chunks)\n",
        "  for iter in range(num_of_chunks):\n",
        "    print('context_chunks len:', len(context_chunks))\n",
        "    context_chunks_as_str = '\\n###\\n'.join([str(elem) for elem in context_chunks])\n",
        "    llm_full_query = prompt_template.format(context=context_chunks_as_str, question=query)\n",
        "    encoding = tiktoken.get_encoding(\"p50k_base\")\n",
        "    num_tokens_template = len(encoding.encode(prompt_template))\n",
        "    num_tokens = len(encoding.encode(llm_full_query))\n",
        "    print('num_tokens', num_tokens)\n",
        "\n",
        "    if len(context_chunks) == 1 and num_tokens > limit_input_tokens - correction_num_of_tokens:\n",
        "      chunk_appendix = '\\n\\nMore details:'\n",
        "      extracted_link = re.search(r'https://.+', context_chunks[0][-100:]).group(0)\n",
        "      chunk_appendix = chunk_appendix + ' ' + extracted_link\n",
        "      num_of_chars_to_cut = num_tokens - limit_input_tokens + num_tokens_template + correction_num_of_tokens\n",
        "      context_chunks[0] = context_chunks[0][:-num_of_chars_to_cut]\n",
        "      context_chunks[0] = context_chunks[0] + chunk_appendix\n",
        "      context_chunks_as_str = '\\n###\\n'.join([str(elem) for elem in context_chunks])\n",
        "      llm_full_query = prompt_template.format(context=context_chunks_as_str, question=query)\n",
        "      num_tokens = len(encoding.encode(llm_full_query))\n",
        "    elif num_tokens > limit_input_tokens - correction_num_of_tokens:\n",
        "      print('context_chunks before truncating:', len(context_chunks))\n",
        "      context_chunks = context_chunks[:-1]\n",
        "      print('context_chunks after truncating:', len(context_chunks))\n",
        "      print(iter)\n",
        "\n",
        "print('Num of context chunks:', len(context_chunks))\n",
        "encoding = tiktoken.get_encoding(\"p50k_base\")\n",
        "num_tokens = len(encoding.encode(llm_full_query))\n",
        "print('Number of tokens in final query: ', num_tokens)"
      ],
      "metadata": {
        "id": "puONH7o4X7-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show final query:\n",
        "#print(llm_full_query)"
      ],
      "metadata": {
        "id": "Swfvr-FaYo7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quering the model\n",
        "Note parameters top_k, top_p, and temperature - can be tuned to improve results.\n",
        "\n",
        "Parameters explained:\n",
        "- https://huggingface.co/blog/how-to-generate\n",
        "- https://www.linkedin.com/pulse/large-language-model-settings-temperature-top-p-max-tokens-albert-mao-0c6ie/"
      ],
      "metadata": {
        "id": "33LG5mCOKwjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('The question:', query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRUqOw5KYVmk",
        "outputId": "c5a8a9c8-3636-4fbf-98cf-ff359eb594db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The question: Give me a hefty loan!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "answer = llm_ctrans(llm_full_query, top_k=40, top_p=0.4, temperature=0.7)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2DCY251Zk0w",
        "outputId": "8f9acf7a-bccd-496f-9b30-b627fb2af257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " You can borrow between £1,000 to £25,000 with fixed monthly payments of up to 60 months for loans up to £15,000, or up to 96 months for loans over £15,000.\n",
            "CPU times: user 4min 25s, sys: 1min 1s, total: 5min 27s\n",
            "Wall time: 3min 5s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_answer = answer.strip()\n",
        "# # Logic to ensure the links are provided at the end of the answer.\n",
        "llm_answer_appendix = ''\n",
        "if 'https://' not in llm_answer[-100:]:\n",
        "  llm_answer_appendix = '\\n\\nMore details:'\n",
        "  for chunk in context_chunks[:3] if len(context_chunks)>=4 else context_chunks:\n",
        "    topic = chunk.split('\\n')[1]\n",
        "    extracted_link = re.search(r'https://.+', chunk[-100:]).group(0)\n",
        "    llm_answer_appendix = llm_answer_appendix + '\\n - ' + topic + ' ' + extracted_link\n",
        "llm_answer = llm_answer + llm_answer_appendix\n",
        "\n",
        "print(llm_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IveJzBJnko3D",
        "outputId": "a685d22d-e0f0-4306-a843-ed62806a1e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You can borrow between £1,000 to £25,000 with fixed monthly payments of up to 60 months for loans up to £15,000, or up to 96 months for loans over £15,000.\n",
            "More details:\n",
            " - Wedding Loans  https://www.hsbc.co.uk/loans/products/wedding-loan/\n",
            " - Personal Loan  https://www.hsbc.co.uk/loans/products/personal/\n"
          ]
        }
      ]
    }
  ]
}